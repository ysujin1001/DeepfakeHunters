import io, os, base64, datetime, uuid, cv2, json
from fastapi import UploadFile
from PIL import Image, ImageOps
from fpdf import FPDF
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate

from config import config
from backend.app.models.newtowk import mtcnn
from ai.modules.Deepfake_Evaluation_MobileNet_v3_final_application_number_option import analyze_image_with_model_type

async def predict_fake(
    file: UploadFile, model_type: str = "korean") -> dict:
    # ë””ë ‰í† ë¦¬
    base_dir = config['BASE_DIR']
    upload_dir = f"{base_dir}/data/uploads"
    os.makedirs(upload_dir, exist_ok=True)
    
    # ì €ì¥ë  íŒŒì¼ëª…
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    unique_id = uuid.uuid4().hex[:6]
    ext = os.path.splitext(file.filename)[1]
    safe_name = f"{timestamp}_{unique_id}{ext}"
    save_path = f"{upload_dir}/{safe_name}"

    # íŒŒì¼ ì €ì¥
    with open(save_path, "wb") as f:
        f.write(await file.read())
        
    # ìˆ˜ì •í•„ìš”(í˜„ì¬ëŠ” ëª¨ë¸ íƒ€ì…ê³¼ ë¬´ê´€í•˜ê²Œ mobilenetv3_deepfake_final ëª¨ë¸ í•˜ë‚˜ë§Œ ì‚¬ìš©ì¤‘)
    pred_label, confidence, report, gradcam_path, fake_intensity = analyze_image_with_model_type(
        path=save_path,
        model_type=model_type,
        visualize=True,
    )

    # âœ… Grad-CAM ì´ë¯¸ì§€ base64 ë³€í™˜
    gradcam_b64 = None
    if gradcam_path and os.path.exists(gradcam_path):
        with open(gradcam_path, "rb") as f:
            gradcam_b64 = base64.b64encode(f.read()).decode("utf-8")

    # âœ… ê²°ê³¼ ë°˜í™˜
    return {
        "pred_label": pred_label,
        "confidence": round(confidence, 2),
        "report": report,
        "gradcam": gradcam_b64,
        "image_path": save_path,
        "fake_probability": round(fake_intensity, 3) if fake_intensity else None,
        "model_type":model_type
    }


async def generate_heatmap_report(request):
    result = await request.json()
    print("ğŸ§¾ [REPORT INPUT] ìˆ˜ì‹ ëœ JSON:", result.keys())

    # âœ… í•„ìˆ˜ í•„ë“œ ê²€ì¦
    required_fields = ["gradcam", "result", "fake_probability", "model_type"]
    missing = [k for k in required_fields if k not in result]
    if missing:
        raise ValueError(f"í•„ìˆ˜ í‚¤ ëˆ„ë½: {missing}")
    result_data = result
    
    # ë””ë ‰í† ë¦¬
    base_dir = config['BASE_DIR']
    result_dir = f"{base_dir}/data/results"
    image_dir = f"{result_dir}/images"
    pdf_dir = f"{result_dir}/pdfs"
    log_dir = f"{result_dir}/logs"
    for data_dir in [image_dir, pdf_dir, log_dir]:
        os.makedirs(data_dir, exist_ok=True)

    # GradCAM ì €ì¥
    gradcam_b64 = result_data["gradcam"]
    gradcam_bytes = base64.b64decode(gradcam_b64)
    gradcam_img = Image.open(io.BytesIO(gradcam_bytes))
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    image_filename = f"gradcam_{timestamp}.png"
    gradcam_path = f"{image_dir}/{image_filename}"
    gradcam_img.save(gradcam_path)

    prompt = PromptTemplate(
        input_variables=["result", "prob", "type"],
        template=(
            "ë„ˆëŠ” ë”¥í˜ì´í¬ íƒì§€ ì „ë¬¸ê°€ì•¼. ì•„ë˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Grad-CAM íˆíŠ¸ë§µì„ í•´ì„í•´.\n\n"
            "ëª¨ë¸ ìœ í˜•: {type}\n"
            "ì˜ˆì¸¡ ê²°ê³¼: {result}\n"
            "ë”¥í˜ì´í¬ í™•ë¥ : {prob:.2f}%\n\n"
            "ë¶‰ì€ìƒ‰ ì˜ì—­ì€ ëª¨ë¸ì´ ë”¥í˜ì´í¬ íŒë‹¨ì˜ ê·¼ê±°ë¡œ ë³¸ ë¶€ë¶„ì´ì•¼. "
            "ì´ ì‹œê° ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ì´ ì–´ë–»ê²Œ íŒë‹¨í–ˆëŠ”ì§€, "
            "í•©ì„± í”ì Â·í”¼ë¶€ ì§ˆê°Â·ì¡°ëª… ì™œê³¡ ë“± ì‹œê°ì  ê·¼ê±°ë¥¼ ê¸°ìˆ ì ìœ¼ë¡œ ë¶„ì„í•´ì¤˜. "
            "ë˜í•œ ì¸ê°„ ì „ë¬¸ê°€ì˜ ê´€ì ì—ì„œ ì‹ ë¢°ë„ì™€ í•œê³„ì ë„ í•¨ê»˜ ì„¤ëª…í•´ì¤˜."
            "ì•„ìš¸ëŸ¬, ì–¸ê¸‰í•˜ì§€ ì•Šì€ ì‹¬ì¸µ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í•¨ê»˜ ìƒì„¸íˆ ì„¤ëª…í•´ì¤˜."
        ),
    )

    llm = ChatOpenAI(model="gpt-4o-mini")

    analysis_text = llm.invoke(
        prompt.format(
            type="í•œêµ­ì¸ ì´ë¯¸ì§€ ë¶„ì„ ëª¨ë¸" if result_data["model_type"] == "korean" else "ì™¸êµ­ì¸ ì´ë¯¸ì§€ ë¶„ì„ ëª¨ë¸",
            result=result_data["result"],
            prob=result_data["fake_probability"] * 100,
        )
    ).content

    # ------------------------------------------------------
    # 3. PDF ë³´ê³ ì„œ ìƒì„±
    # ------------------------------------------------------
    pdf = FPDF()
    pdf.add_page()

    # ì œëª©
    pdf.add_font("malgun", "", r"C:\Windows\Fonts\malgun.ttf", uni=True)   # ì¼ë°˜
    pdf.add_font("malgun", "B", r"C:\Windows\Fonts\malgunbd.ttf", uni=True)   # êµµì€ì²´
    pdf.set_font("malgun", "B", size=16)
    pdf.cell(0, 10, "ë”¥í˜ì´í¬ íˆíŠ¸ë§µ ë¶„ì„ ë³´ê³ ì„œ", ln=True, align="C")

    # (1) ë¶„ì„ ê°œìš”
    pdf.set_font("malgun", "B", size=13)
    pdf.cell(0, 10, "1. ë¶„ì„ ê°œìš”", ln=True)
    pdf.set_font("malgun", size=11)

    model_name = result_data.get("model_name", "MobileNetV3-Small (PyTorch)")
    model_type = "í•œêµ­ì¸ ì „ìš© ëª¨ë¸" if result_data["model_type"] == "korean" else "ì™¸êµ­ì¸ ì „ìš© ëª¨ë¸"
    analyzed_at = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    pdf.multi_cell(
        0,
        8,
        f"- ëª¨ë¸ëª…: {model_name}\n"
        f"- ëª¨ë¸ ìœ í˜•: {model_type}\n"
        f"- ë¶„ì„ ì¼ì‹œ: {analyzed_at}\n"
        f"- ì˜ˆì¸¡ ê²°ê³¼: {result_data['result']}\n"
        f"- ë”¥í˜ì´í¬ í™•ë¥ : {(result_data['fake_probability'] * 100):.2f}%\n",
    )

    # (2) Grad-CAM ì‹œê°í™”
    pdf.ln(8)
    pdf.set_font("malgun", "B", 13)
    pdf.cell(0, 10, "2. Grad-CAM ì‹œê°í™”", ln=True)
    pdf.image(gradcam_path, x=25, y=pdf.get_y() + 5, w=160)
    pdf.ln(95)

    # (3) LangChain ê¸°ë°˜ AI í•´ì„
    pdf.set_font("malgun", "B", 13)
    pdf.cell(0, 10, "3ï¸. LangChain ê¸°ë°˜ AI í•´ì„", ln=True)
    pdf.set_font("malgun", size=11)
    pdf.multi_cell(0, 7, analysis_text)

    # (4) ê²°ë¡  ë° ê¶Œì¥ ì¡°ì¹˜
    pdf.ln(5)
    pdf.set_font("malgun", "B", 13)
    pdf.cell(0, 10, "4ï¸. ê²°ë¡  ë° ê¶Œì¥ ì¡°ì¹˜", ln=True)
    pdf.set_font("malgun", size=11)
    pdf.multi_cell(
        0,
        7,
        "ë³¸ ë¶„ì„ì€ Grad-CAM ì‹œê° ì£¼ëª©ë„ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
        "AIì˜ ê²°ê³¼ëŠ” ì°¸ê³ ìš©ìœ¼ë¡œ ì‚¬ìš©í•´ì•¼ í•˜ë©°, ë²•ì  íŒë‹¨ì´ë‚˜ ê³µì‹ ì¦ê±°ë¡œ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
        "ê²°ê³¼ì˜ ì‹ ë¢°ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ì†ŒìŠ¤ë¡œ êµì°¨ ê²€ì¦ì„ ê¶Œì¥í•©ë‹ˆë‹¤.",
    )

    # PDF ì €ì¥
    pdf_filename = f"heatmap_report_{timestamp}.pdf"
    pdf_path = f"{pdf_dir}/{pdf_filename}"
    pdf.output(pdf_path)

    # ------------------------------------------------------
    # 4. ë¡œê·¸ JSON ìƒì„± (DB ì—°ë™ ëŒ€ë¹„)
    # ------------------------------------------------------
    log_data = {
        "created_at": analyzed_at,
        "model_name": model_name,
        "model_type": model_type,
        "result": result_data["result"],
        "fake_probability": result_data["fake_probability"],
        "gradcam_image": gradcam_path,
        "pdf_path": pdf_path,
    }

    log_filename = f"report_log_{timestamp}.json"
    with open(f"{log_dir}/{log_filename}", "w", encoding="utf-8") as f:
        json.dump(log_data, f, indent=4, ensure_ascii=False)

    # ìµœì¢… PDF ê²½ë¡œ ë°˜í™˜
    return pdf_path

# ë¯¸êµ¬í˜„
async def face_detect(file):
    base_dir = config['BASE_DIR']
    output_dir = f"{base_dir}/cropped_faces"
    os.makedirs(output_dir, exist_ok=True)
    
    cv_img = cv2.imread(file)
    cv_img = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)
    img = Image.fromarray(cv_img)
    width, height = img.size

    boxes, probs = mtcnn.detect(img)
    if boxes is None:
        print(f"\nâŒ ì–¼êµ´ ë¯¸ê²€ì¶œ: {file}")

    for i, (box, prob) in enumerate(zip(boxes, probs)):
        if prob < 0.9:
            continue

        x1, y1, x2, y2 = box
        w, h = x2 - x1, y2 - y1
        margin = 0.2
        x1 = max(0, int(x1 - w * margin / 2))
        y1 = max(0, int(y1 - h * margin / 2))
        x2 = min(width, int(x2 + w * margin / 2))
        y2 = min(height, int(y2 + h * margin / 2))

        face = img.crop((x1, y1, x2, y2))
        face.thumbnail((224, 224), Image.BICUBIC)
        face = ImageOps.pad(face, (224, 224), color=(0, 0, 0))

        out_name = f"{os.path.splitext(file)[0]}_face{i+1}.jpg"
        out_path = f"{output_dir}/{out_name}"
        face.save(out_path, format="JPEG", quality=95)
    return out_path
